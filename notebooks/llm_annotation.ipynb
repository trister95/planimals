{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import langchain\n",
    "import openai\n",
    "import re\n",
    "from environs import Env\n",
    "from tqdm import tqdm\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnableMap, RunnablePassthrough\n",
    "from langchain.output_parsers.json import SimpleJsonOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_df = pd.read_csv(\"data/sentences/sentence_df.csv\")\n",
    "sample = sentence_df.sample(n=1000)\n",
    "sentences = sample[\"sentence\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No language found for: ƒ 1-2-0 663\n"
     ]
    }
   ],
   "source": [
    "from planimals.utils.has_letter import has_letter\n",
    "from langdetect import detect\n",
    "\n",
    "filtered_lst = [s for s in sentences if has_letter(s)]\n",
    "\n",
    "dutch_lst = []\n",
    "\n",
    "for s in filtered_lst:\n",
    "  try:\n",
    "    language = detect(s)\n",
    "    if language in [\"nl\", \"af\"]:\n",
    "      dutch_lst.append(s)\n",
    "  except:\n",
    "    print(f\"No language found for: {s}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Env()\n",
    "env.read_env(\".env\")  # Read .env file\n",
    "OPENAI_API_KEY = env(\"OPENAI_API_KEY\")  # Get the API key\n",
    "OPEN_AI_TOKEN_I_PRICE = 0.003/1000  # Replace X with the current price per token from OpenAI's pricing\n",
    "OPEN_AI_TOKEN_O_PRICE = 0.006/1000\n",
    "openai.api_key = OPENAI_API_KEY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_indices(sentence, word):\n",
    "    #check if -1 is needed for IOB notation\n",
    "    start_index = sentence.find(word)\n",
    "    end_index = start_index + len(word)\n",
    "    return [start_index, end_index]\n",
    "\n",
    "def has_multiple_occurrences(sentence, model_output):\n",
    "    for category in model_output:\n",
    "        for word in model_output[category]:\n",
    "            if sentence.count(word) > 1:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def transform_output(sentence, model_output):\n",
    "    labels = []\n",
    "    flagged = False\n",
    "\n",
    "    # If multiple occurences, you should annotate manually\n",
    "    if has_multiple_occurrences(sentence, model_output):\n",
    "        return {\"Sentence\": sentence, \"Labels\": [], \"Flagged\": True}\n",
    "\n",
    "    for category in model_output.keys():\n",
    "        for word in model_output[category]:\n",
    "            indices = find_indices(sentence, word)\n",
    "            if indices:\n",
    "                labels.append(indices + [category])  # 'animal' or 'plant'\n",
    "\n",
    "    return {\"Sentence\": sentence, \"Labels\": labels, \"Flagged\": flagged}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"You'll analyze Old Dutch sentences to identify plants and animals. Given a sentence provide the following fields in a JSON dict: 'plants', 'animals'. Remember: Tag only explicit references to plants or animals. Ignore plant/animal parts, products, and habitats. No tagging of particles. Tag only the nouns that directly refer to the plant or animal, excluding adjectives that are not part of a species' common name or a proper noun. Tag literally (use the exact same spelling as in the Dutch sentence). Text: {x}\")\n",
    "model = ChatOpenAI(model=\"ft:gpt-3.5-turbo-1106:personal::8KmdqIHA\")\n",
    "map_ = RunnableMap(x=RunnablePassthrough())\n",
    "chain = (\n",
    "    map_\n",
    "    | prompt\n",
    "    | model\n",
    "    | SimpleJsonOutputParser()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_token_count(text):\n",
    "    return len(str(text)) / 4\n",
    "\n",
    "\n",
    "def process_batch(batch):\n",
    "    input_token_count = 0\n",
    "    output_token_count = 0\n",
    "    results = []\n",
    "\n",
    "    for sentence in batch:\n",
    "        # Count input tokens\n",
    "        input_tokens = estimate_token_count(sentence)\n",
    "        input_token_count += input_tokens\n",
    "\n",
    "        # API call\n",
    "        response = chain.invoke(sentence)\n",
    "\n",
    "        # Count output tokens\n",
    "        output_tokens = estimate_token_count(response)\n",
    "        output_token_count += output_tokens\n",
    "\n",
    "        # Process response\n",
    "        tagged = transform_output(sentence, response)\n",
    "        results.append(tagged)\n",
    "\n",
    "    return results, input_token_count, output_token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 39/39 [03:54<00:00,  6.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated input cost: 0.08444025000000001\n",
      "Estimated output cost: 0.034767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "batch_size = 20  # Adjust based on your needs and API limitations\n",
    "batches = [dutch_lst[i:i + batch_size] for i in range(0, len(dutch_lst), batch_size)]\n",
    "\n",
    "total_input_tokens = 0\n",
    "total_output_tokens = 0\n",
    "for batch in tqdm(batches, desc=\"Processing batches\"):\n",
    "    batch_results, batch_input_tokens, batch_output_tokens = process_batch(batch)\n",
    "    results.extend(batch_results)\n",
    "    total_input_tokens += batch_input_tokens\n",
    "    total_output_tokens += batch_output_tokens\n",
    "\n",
    "print(f\"Estimated input cost: {total_input_tokens*OPEN_AI_TOKEN_I_PRICE}\")\n",
    "print(f\"Estimated output cost: {total_output_tokens*OPEN_AI_TOKEN_O_PRICE}\")\n",
    "\n",
    "# Create and save DataFrame\n",
    "df = pd.DataFrame(results, columns=[\"Sentence\", \"Labels\", \"Flagged\"])\n",
    "df.to_csv(\"plants_animals.csv\", index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
