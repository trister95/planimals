{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../src/utils.py\n",
    "%run ../src/llm_annotation.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Env()\n",
    "env.read_env(\".env\")  # Read .env file\n",
    "OPENAI_API_KEY = env(\"OPENAI_API_KEY\")  # Get the API key\n",
    "OPEN_AI_TOKEN_I_PRICE = 0.003 / 1000\n",
    "OPEN_AI_TOKEN_O_PRICE = 0.006 / 1000\n",
    "openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = 5000\n",
    "list_of_dfs = [df.iloc[i:i+num_rows] for i in range(0, df.shape[0], num_rows)]\n",
    "\n",
    "for n, part_df in enumerate(list_of_dfs):\n",
    "    filename = f\"df_{n+1}_part.csv\"\n",
    "    part_df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2ndbatch = pd.read_csv(\"/home/arjan_v_d/planimals/notebooks/df_2_part.csv\")\n",
    "sentences = df_2ndbatch[\"sentences\"].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed to LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"You'll analyze Old Dutch sentences to identify plants and animals. Given a sentence provide the following fields in a JSON dict: 'plants', 'animals'. Remember: Tag only explicit references to plants or animals. Ignore plant/animal parts, products, and habitats. No tagging of particles. Tag only the nouns that directly refer to the plant or animal, excluding adjectives that are not part of a species' common name or a proper noun. Tag literally (use the exact same spelling as in the Dutch sentence). Text: {x}\"\n",
    ")\n",
    "model = ChatOpenAI(model=\"ft:gpt-3.5-turbo-1106:personal::8KmdqIHA\")\n",
    "map_ = RunnableMap(x=RunnablePassthrough())\n",
    "chain = map_ | prompt | model | SimpleJsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100  # Adjust based on your needs and API limitations\n",
    "batches = [sentences[i : i + batch_size] for i in range(0, len(sentences), batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|██████████| 50/50 [15:40<00:00, 18.81s/it]\n"
     ]
    }
   ],
   "source": [
    "results = await process_all_batches(batches, chain)\n",
    "df = pd.DataFrame(results, columns=[\"sentence\", \"label\", \"flagged\"])\n",
    "df.to_csv(\"output_2ndbatch.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual annotations of flagged sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select flagged sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"plants_animals.csv\")\n",
    "df_flagged = df[df[\"flagged\"]==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'flagged_from_first5000.jsonl' created successfully.\n"
     ]
    }
   ],
   "source": [
    "dataframe_column_to_jsonl(df_flagged, 'sentence', 'flagged_from_first5000.jsonl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When annotated manually with doccano, update the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_doccano_annotations = \"manual_annotations_first_5000.jsonl\"\n",
    "#df = pd.read_csv(\"/home/arjan_v_d/planimals/data/plants_animals.csv\")\n",
    "#df['Labels'] = df['Labels'].apply(ast.literal_eval)\n",
    "\n",
    "updated_df = update_dataframe_with_annotations(df, path_to_doccano_annotations, 'sentence', 'label', 'flagged') #check if labels are the sames still"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_df.to_csv(\"first_5000_sentences_after_manual.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform to IOB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag2id = {\n",
    "    \"O\": 0,\n",
    "    \"B-animals\": 1,\n",
    "    \"I-animals\": 2,\n",
    "    \"B-plants\": 3,\n",
    "    \"I-plants\": 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['De', 'blauwe', 'vinvis', 'zwom', 'machtig', 'snel', '.'],\n",
       " ['O', 'B-animals', 'I-animals', 'O', 'O', 'O', 'O'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_words_punct, new_labels_punct = apply_labels_to_tokens_including_punctuation(\n",
    "    sentence, labeled_spans, tag2id\n",
    ")\n",
    "new_words_punct, new_labels_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_labels = convert_labels_to_numeric(new_labels_punct, tag2id)\n",
    "numeric_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 rows are not taken into account\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"first_5000_sentences_after_manual.csv\")\n",
    "df['has_label'] = df['label'].apply(lambda x: bool(re.search(r'\\[.+\\]', str(x))))\n",
    "filtered_df = df[df['flagged'] != True]\n",
    "\n",
    "print(f\"{len(df)- len(filtered_df)} rows are not taken into account\")\n",
    "\n",
    "df_labels = filtered_df[(filtered_df[\"has_label\"]==True)]\n",
    "df_no_labels = filtered_df[(filtered_df[\"has_label\"]==False)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negatives = df_no_labels.sample(n=len(df_labels))\n",
    "\n",
    "training_df = pd.concat([df_labels, negatives])\n",
    "training_df = training_df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df[['sentence', 'label']] = training_df.apply(lambda row: process_row(row), axis=1, result_type='expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df.drop(columns = [\"Unnamed: 0\", \"flagged\", \"has_label\", \"words\", \"numeric_labels\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df.to_csv(\"gemelijke_grillen.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
