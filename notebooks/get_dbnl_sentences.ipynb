{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8eNUNUYj-w0d"
   },
   "source": [
    "## Clone, install, import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7wJk2cZN9lf-",
    "outputId": "d8c74583-e407-46f7-81f5-7ddb2e9e8927",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!git clone #add link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r /home/arjan_v_d/planimals/requirements.txt\n",
    "\n",
    "import fastparquet\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JxMAqL-Z-_2G",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "I9ThYhJj-6Ja"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory ../data/dbnl_xml already exists\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/arjan_v_d/planimals/notebooks/get_dbnl_sentences.ipynb Cell 5\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/arjan_v_d/planimals/notebooks/get_dbnl_sentences.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mrun\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m/home/arjan_v_d/planimals/src/utils.py\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/arjan_v_d/planimals/notebooks/get_dbnl_sentences.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m create_if_absent(\u001b[39m\"\u001b[39m\u001b[39m../data/dbnl_xml\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/arjan_v_d/planimals/notebooks/get_dbnl_sentences.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m download_and_unzip(url \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mhttps://www.dbnl.org/letterkunde/pd/xml_pd.zip\u001b[39;49m\u001b[39m\"\u001b[39;49m, output_dir \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m../data/dbnl_xml\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/planimals/src/utils.py:53\u001b[0m, in \u001b[0;36mdownload_and_unzip\u001b[0;34m(url, output_dir)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdownload_and_unzip\u001b[39m(url, output_dir \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     52\u001b[0m     \u001b[39m# Download the zipfile\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m     filename, _ \u001b[39m=\u001b[39m urllib\u001b[39m.\u001b[39;49mrequest\u001b[39m.\u001b[39;49murlretrieve(url)\n\u001b[1;32m     55\u001b[0m     \u001b[39m# Unzip the zipfile\u001b[39;00m\n\u001b[1;32m     56\u001b[0m     \u001b[39mwith\u001b[39;00m zipfile\u001b[39m.\u001b[39mZipFile(filename, \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m zip_ref:\n",
      "File \u001b[0;32m/usr/lib/python3.11/urllib/request.py:270\u001b[0m, in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    267\u001b[0m     reporthook(blocknum, bs, size)\n\u001b[1;32m    269\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 270\u001b[0m     block \u001b[39m=\u001b[39m fp\u001b[39m.\u001b[39;49mread(bs)\n\u001b[1;32m    271\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m block:\n\u001b[1;32m    272\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.11/http/client.py:466\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m amt \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength:\n\u001b[1;32m    464\u001b[0m     \u001b[39m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    465\u001b[0m     amt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength\n\u001b[0;32m--> 466\u001b[0m s \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfp\u001b[39m.\u001b[39mread(amt)\n\u001b[1;32m    467\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m s \u001b[39mand\u001b[39;00m amt:\n\u001b[1;32m    468\u001b[0m     \u001b[39m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    469\u001b[0m     \u001b[39m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    470\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m/usr/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    707\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.11/ssl.py:1311\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1307\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1308\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1309\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1310\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1311\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1312\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1313\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/usr/lib/python3.11/ssl.py:1167\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1165\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1166\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1167\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1168\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1169\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%run /home/arjan_v_d/planimals/src/utils.py\n",
    "create_if_absent(\"../data/dbnl_xml\")\n",
    "download_and_unzip(url = \"https://www.dbnl.org/letterkunde/pd/xml_pd.zip\", output_dir = \"../data/dbnl_xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-UAHKveR_KtO"
   },
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "98TjeKar_GKR"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lxml.etree'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/planimals/src/preprocessing.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlxml\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39metree\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mET\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mhtml\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mentities\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mucto\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lxml.etree'"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lxml.etree'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/arjan_v_d/planimals/notebooks/get_dbnl_sentences.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/arjan_v_d/planimals/notebooks/get_dbnl_sentences.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mrun\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m/home/arjan_v_d/planimals/src/preprocessing.py\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/arjan_v_d/planimals/notebooks/get_dbnl_sentences.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlxml\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39metree\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/arjan_v_d/planimals/notebooks/get_dbnl_sentences.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m html_to_decimal_dict \u001b[39m=\u001b[39m make_html_entity_dict()\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/arjan_v_d/planimals/notebooks/get_dbnl_sentences.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m addition \u001b[39m=\u001b[39m  additional_declaration_str(html_to_decimal_dict, \u001b[39m'\u001b[39m\u001b[39m.dtd\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lxml.etree'"
     ]
    }
   ],
   "source": [
    "%run /home/arjan_v_d/planimals/src/preprocessing.py\n",
    "import lxml.etree\n",
    "\n",
    "html_to_decimal_dict = make_html_entity_dict()\n",
    "addition =  additional_declaration_str(html_to_decimal_dict, '.dtd\"')\n",
    "add_declaration_to_xml('../data/dbnl_xml', '<!DOCTYPE', '.dtd\"', addition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "id": "HcWUpuin_Oqn",
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory dbnl_txt created\n",
      "file teen002bijz01 could not be parsed\n",
      "file hugo001piad01 could not be parsed\n",
      "file vaen001quin01 could not be parsed\n",
      "file vry_001anat01 could not be parsed\n",
      "file _gid001183901 could not be parsed\n",
      "file luyk001jezu01 could not be parsed\n",
      "file aa__001biog02 could not be parsed\n",
      "file herl001besc01 could not be parsed\n",
      "file lede003drie01 could not be parsed\n",
      "file elge001zinn01 could not be parsed\n",
      "file ferm001nieu01 could not be parsed\n",
      "file leuv001amor01 could not be parsed\n",
      "file aa__001biog11 could not be parsed\n",
      "file carp002verh01 could not be parsed\n"
     ]
    }
   ],
   "source": [
    "create_if_absent(\"dbnl_txt\")\n",
    "dbnl_to_txt(\"dbnl_xml\", \"dbnl_txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "E3OwXGIp_hDZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory dbnl_folia already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "looping through text files: 100%|██████████| 3415/3415 [38:02<00:00,  1.50it/s]  \n"
     ]
    }
   ],
   "source": [
    "create_if_absent(\"dbnl_folia\")\n",
    "txt_to_folia(\"dbnl_txt\", \"dbnl_folia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "phEEWsLOAkxY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory dbnl_sentences already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "making df:   0%|          | 0/3415 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fordbnl_folia/_sta001stat02.folia.xml it didn't work\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "making df: 100%|██████████| 3415/3415 [01:25<00:00, 39.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fordbnl_folia/_vor003vors01.folia.xml it didn't work\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "create_if_absent(\"dbnl_sentences\")\n",
    "folia_files = select_all_files(\"dbnl_folia\", \"folia.xml\")\n",
    "\n",
    "for f in tqdm.tqdm(folia_files, desc = \"making df\"):\n",
    "  folia_to_df(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 things: text in sentence, dutch, footnotes. Add that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in 'dbnl_xml': 3433\n",
      "Number of files in 'dbnl_txt': 3415\n",
      "Number of files in 'dbnl_folia': 3422\n",
      "Number of files in 'dbnl_sentences': 3413\n"
     ]
    }
   ],
   "source": [
    "def count_files_in_folder(folder_path):\n",
    "    file_count = 0\n",
    "\n",
    "    # Iterate over all the items in the folder\n",
    "    for _, _, files in os.walk(folder_path):\n",
    "        file_count += len(files)\n",
    "\n",
    "    return file_count\n",
    "\n",
    "# Provide the path to the folder you want to count files in\n",
    "folder_paths = ['dbnl_xml', 'dbnl_txt', 'dbnl_folia', 'dbnl_sentences']\n",
    "\n",
    "for p in folder_paths:\n",
    "    num_files = count_files_in_folder(p)\n",
    "    print(f\"Number of files in '{p}': {num_files}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "subfolders1 = [\"towards_big_df/subfolder_1\", \"towards_big_df/subfolder_2\", \"towards_big_df/subfolder_3\", \"towards_big_df/subfolder_4\", \"towards_big_df/subfolder_5\"]\n",
    "subfolders2 = [\"towards_big_df/subfolder_5\", \"towards_big_df/subfolder_6\", \"towards_big_df/subfolder_7\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reading pkl's: 100%|██████████| 500/500 [00:10<00:00, 46.04it/s]\n",
      "reading pkl's: 100%|██████████| 500/500 [00:12<00:00, 40.03it/s] \n",
      "reading pkl's: 100%|██████████| 500/500 [00:14<00:00, 35.16it/s]\n",
      "reading pkl's: 100%|██████████| 500/500 [00:15<00:00, 33.32it/s] \n",
      "reading pkl's: 100%|██████████| 500/500 [00:13<00:00, 38.28it/s] "
     ]
    }
   ],
   "source": [
    "def select_all_files(path_to_folder, file_extension):\n",
    "  return [os.path.join(path_to_folder, f) for f in os.listdir(path_to_folder) if f.endswith(file_extension)]\n",
    "\n",
    "n = 0\n",
    "for s in subfolders1:\n",
    "    n+=1\n",
    "    paths = select_all_files(s, \".pkl\")\n",
    "    dfs = []\n",
    "    for p in tqdm.tqdm(paths, desc = \"reading pkl's\"):\n",
    "        df = pd.read_pickle(p)\n",
    "        dfs.append(df)\n",
    "    total_df = pd.concat(dfs, ignore_index = True)\n",
    "    total_df.to_pickle(f\"towards_big_df_sub_{n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reading pkl's: 100%|██████████| 500/500 [00:14<00:00, 33.75it/s]\n",
      "reading pkl's: 100%|██████████| 500/500 [00:11<00:00, 44.23it/s] \n",
      "reading pkl's: 100%|██████████| 413/413 [00:11<00:00, 36.02it/s]\n"
     ]
    }
   ],
   "source": [
    "n = 5\n",
    "for s in subfolders2:\n",
    "    n+=1\n",
    "    paths = select_all_files(s, \".pkl\")\n",
    "    dfs = []\n",
    "    for p in tqdm.tqdm(paths, desc = \"reading pkl's\"):\n",
    "        df = pd.read_pickle(p)\n",
    "        dfs.append(df)\n",
    "    total_df = pd.concat(dfs, ignore_index = True)\n",
    "    total_df.to_pickle(f\"towards_big_df_sub_{n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the source folder containing the files\n",
    "source_folder = \"dbnl_sentences\"\n",
    "\n",
    "# Define the destination folder for the subfolders\n",
    "destination_folder = \"towards_big_df\"\n",
    "\n",
    "# Create the destination folder if it doesn't exist\n",
    "os.makedirs(destination_folder, exist_ok=True)\n",
    "\n",
    "# Get a list of all the files in the source folder\n",
    "files = os.listdir(source_folder)\n",
    "\n",
    "# Calculate the number of files per subfolder\n",
    "files_per_subfolder = 500\n",
    "\n",
    "# Calculate the total number of subfolders needed\n",
    "total_subfolders = len(files) // files_per_subfolder + 1\n",
    "\n",
    "# Create the subfolders and move the files into them\n",
    "for i in range(total_subfolders):\n",
    "    # Create a subfolder\n",
    "    subfolder_path = os.path.join(destination_folder, f'subfolder_{i+1}')\n",
    "    os.makedirs(subfolder_path, exist_ok=True)\n",
    "    \n",
    "    # Move the files into the subfolder\n",
    "    start_index = i * files_per_subfolder\n",
    "    end_index = start_index + files_per_subfolder\n",
    "    for file in files[start_index:end_index]:\n",
    "        file_path = os.path.join(source_folder, file)\n",
    "        shutil.move(file_path, subfolder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = \"towards_big_df_sub_1\"\n",
    "df2 = \"towards_big_df_sub_2\"\n",
    "df3 = \"towards_big_df_sub_3\"\n",
    "df4 = \"towards_big_df_sub_4\"\n",
    "df5 = \"towards_big_df_sub_5\"\n",
    "df6 = \"towards_big_df_sub_6\"\n",
    "df7 = \"towards_big_df_sub_7\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = df5\n",
    "f = \"df5\" \n",
    "e_df = pd.read_pickle(e)\n",
    "e_df.to_parquet(f'parquets/{f}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.concat([\n",
    "    pd.read_parquet('parquets/df1.parquet'),\n",
    "    pd.read_parquet('parquets/df2.parquet'),\n",
    "    pd.read_parquet('parquets/df3.parquet'),\n",
    "    pd.read_parquet('parquets/df4.parquet'),\n",
    "    pd.read_parquet('parquets/df5.parquet'),\n",
    "    pd.read_parquet('parquets/df6.parquet'),\n",
    "    pd.read_parquet('parquets/df7.parquet')],\n",
    "    ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.concat([\n",
    "    pd.read_parquet('parquets/df1.parquet'),\n",
    "    pd.read_parquet('parquets/df2.parquet')],\n",
    "    ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_parquet(\"parquets/df1and2.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "a = pd.read_parquet(\"parquets/df1and2.parquet\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
